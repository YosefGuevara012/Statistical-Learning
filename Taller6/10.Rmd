---

output: word_document
---


10. We have seen that as the number of features used in a model increases, the training error will necessarily decrease, but the test error may not. We will now explore this in a simulated data set.

```{r, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(ISLR)
library(corrplot)
library(RColorBrewer)
library(car)
library(class)
library(MASS)
library(boot)
library(glmnet)
library(pls)
library(leaps)
```

(a) Generate a data set with p = 20 features, n = 1,000 observations, and an associated quantitative response vector generated according to the model.

where β has some elements that are exactly equal to zero.

```{r, warning=FALSE}
set.seed(1)
eps <- rnorm(1000)
xmat <- matrix(rnorm(1000*20), ncol=20)
betas <- sample(-5:5, 20, replace=TRUE)
betas[c(3,6,7,10,13,17)] <- 0
betas
y <- xmat %*% betas + eps
```

(b) Split your data set into a training set containing 100 observations and a test set containing 900 observations.

```{r}
train <- sample(seq(1000), 100, replace = FALSE)
test <- -train
x.train <- xmat[train, ]
x.test <- xmat[test, ]
y.train <- y[train]
y.test <- y[test]
```

El conjunto de datos de entrenamiento ahora tiene 100 observaciones y el de prueba cuenta con las 900 observaciones requeridas.


(c) Perform best subset selection on the training set, and plot the training set MSE associated with the best model of each size.

```{r}
data.train <- data.frame(y = y.train, x = x.train)
mod.full <- regsubsets(y ~ ., data = data.train, nvmax = 20)
train.mat <- model.matrix(y ~ ., data = data.train, nvmax = 20)
val.errors <- rep(NA, 20)
for (i in 1:20) {
    coefi <- coef(mod.full, id = i)
    pred <- train.mat[, names(coefi)] %*% coefi
    val.errors[i] <- mean((pred - y.train)^2)
}
plot(val.errors, xlab = "Predictores", ylab = "MSE de Entrenamiento", pch = 15, type = "b")
```
(d) Plot the test set MSE associated with the best model of each size.

```{r}
data.test <- data.frame(y = y.test, x = x.test)
test.mat <- model.matrix(y ~ ., data = data.test, nvmax = 20)
val.errors <- rep(NA, 20)
for (i in 1:20) {
    coefi <- coef(mod.full, id = i)
    pred <- test.mat[, names(coefi)] %*% coefi
    val.errors[i] <- mean((pred - y.test)^2)
}
plot(val.errors, xlab = "Predictores", ylab = "MSE de Prueba", pch = 15, type = "b")
```

(e) For which model size does the test set MSE take on its minimum value? Comment on your results. If it takes on its minimum value for a model containing only an intercept or a model containing all of the features, then play around with the way that you are
generating the data in (a) until you come up with a scenario in which the test set MSE is minimized for an intermediate model size.

Mediante la función 'Which.min()' se determina el mínimo del vector asociado al error para saber con cuantas de las varibles dicho error disminuye.

```{r}
which.min(val.errors)
```
El menor error se obtiene del modelo con 14 variables o predictores.


(f) How does the model at which the test set MSE is minimized compare to the true model used to generate the data? Comment on the coefficient values.

```{r}
coef(mod.full, which.min(val.errors))
```

(g) Create a plot displaying for a range of values of r, where βˆjr is the jth coefficient estimate for the best model containing r coefficients. Comment on what you observe. How does this compare to the test MSE plot from (d)?

```{r}
val.errors <- rep(NA, 20)
x_cols = colnames(xmat, do.NULL = FALSE, prefix = "x.")
for (i in 1:20) {
    coefi <- coef(mod.full, id = i)
    val.errors[i] <- sqrt(sum((betas[x_cols %in% names(coefi)] - coefi[names(coefi) %in% x_cols])^2) + sum(betas[!(x_cols %in% names(coefi))])^2)
}
plot(val.errors, xlab = "Coeficientes", ylab = "", pch = 15, type = "b")
```
Se logra evidenciar nuevamente que el modelo con 14 variables es el que minimiza el error, pero además los modelos con más varialbes, también resultan ser convenientes ya que el error es muy pequeño. 

