---
output: word_document
---

8. We will now perform cross-validation on a simulated data set.

(a) Generate a simulated data set as follows

```{r}
set.seed(1)
y=rnorm (100)
x=rnorm (100)
y=x-2*x^2+ rnorm (100)
```

In this data set, what is **n** and what is **p**? Write out the model
used to generate the data in equation form.

Tenemos que $n=100$ y $p=2$, el modelo usado para generar esta data es:

$$y=x -2x^2 +\varepsilon$$
$$\varepsilon \sim N(0,1)$$

(b) Create a scatterplot of X against Y . Comment on what you find.

```{r}

plot(x,y, main="x vs. y", col="blue")

```
Se observa claramente una relación curva entre **x** y **y** 

(c) Set a random seed, and then compute the LOOCV errors that
result from fitting the following four models using least squares:

```{r}
library(boot)
### se crea un data frame para facilitar la manipulación de los datos
Data <- as.data.frame(cbind(x, y))
set.seed(1)
```

$$i. Y= \beta_0 + \beta_1X + \varepsilon$$

```{r}

glm.fit1 <- glm(y ~ x)
cv.error1<-cv.glm(Data, glm.fit1)$delta
cv.error1[1]
```
La función cv.error<-cv.glm() produce una lista con varios componentes. Los dos
números del vector delta contienen los resultados de la validación cruzada. En este caso los números son idénticos (hasta dos decimales) y corresponden
a la estadística LOOCV dada en.xxxxx

$$ii. Y= \beta_0 + \beta_1X +  \beta_2X^2 + \varepsilon$$

```{r}
glm.fit2 <- glm(y ~ poly(x, 2))
cv.error2<-cv.glm(Data, glm.fit2)$delta
cv.error2[1]
```

$$iii. Y= \beta_0 + \beta_1X  + \beta_2X^2 + \beta_3X^3 + \varepsilon$$

```{r}
glm.fit3 <- glm(y ~ poly(x, 3))
cv.error3<-cv.glm(Data, glm.fit3)$delta
cv.error3[1]
```

$$iv. Y= \beta_0 + \beta_1X  + \beta_2X^2 + \beta_3X^3 + \beta_4X^4 + \varepsilon$$

```{r}
glm.fit4 <- glm(y ~ poly(x, 4))
cv.error4<-cv.glm(Data, glm.fit4)$delta
cv.error4[1]
```


(d) Repeat (c) using another random seed, and report your results.
Are your results the same as what you got in (c)? Why?


```{r}

set.seed(10)
glm.fit1 <- glm(y ~ x)
cv.error1<-cv.glm(Data, glm.fit1)$delta
cv.error1[1]
```
```{r}
glm.fit2 <- glm(y ~ poly(x, 2))
cv.error2<-cv.glm(Data, glm.fit2)$delta
cv.error2[1]
```

```{r}
glm.fit3 <- glm(y ~ poly(x, 3))
cv.error3<-cv.glm(Data, glm.fit3)$delta
cv.error3[1]
```


```{r}
glm.fit4 <- glm(y ~ poly(x, 4))
cv.error4<-cv.glm(Data, glm.fit4)$delta
cv.error4[1]
```

Los resultados son idénticos debido a que LOOCV solo usa una observación para validar el modelo, las demás observaciones son usadas para el entrenamiento.

(e) Which of the models in (c) had the smallest LOOCV error? Is
this what you expected? Explain your answer.


El error cuadrático medio **MSE**  más pequeño corresponde estimado por el LOOCV el modelo **glm.fit2**, puesto que como se establecido al durante la simulación del ejercicio la relación entre las variable es cuadrática.



(f) Comment on the statistical significance of the coefficient estimates
that results from fitting each of the models in (c) using
least squares. Do these results agree with the conclusions drawn
based on the cross-validation results?

```{r}
summary(glm.fit4)

```

Gracia al p-value se identifica que solo los coeficientes $\beta_1$ y $\beta_2$, que acompañan a los términos linear y cuadratico respectivamente son significativos. Tanto el **AIC** como la **deviación residual muestran** un buen ajuste del modelo dado que sus valores no son muy grande.

